{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'DtypeArg | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mconvert_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mconvert_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnumpy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprecise_float\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdate_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoding_errors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'strict'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'CompressionOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'StorageOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Convert a JSON string to pandas object.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "path_or_buf : a valid JSON str, path object or file-like object\n",
      "    Any valid string path is acceptable. The string could be a URL. Valid\n",
      "    URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
      "    expected. A local file could be:\n",
      "    ``file://localhost/path/to/table.json``.\n",
      "\n",
      "    If you want to pass in a path object, pandas accepts any\n",
      "    ``os.PathLike``.\n",
      "\n",
      "    By file-like object, we refer to objects with a ``read()`` method,\n",
      "    such as a file handle (e.g. via builtin ``open`` function)\n",
      "    or ``StringIO``.\n",
      "orient : str\n",
      "    Indication of expected JSON string format.\n",
      "    Compatible JSON strings can be produced by ``to_json()`` with a\n",
      "    corresponding orient value.\n",
      "    The set of possible orients is:\n",
      "\n",
      "    - ``'split'`` : dict like\n",
      "      ``{index -> [index], columns -> [columns], data -> [values]}``\n",
      "    - ``'records'`` : list like\n",
      "      ``[{column -> value}, ... , {column -> value}]``\n",
      "    - ``'index'`` : dict like ``{index -> {column -> value}}``\n",
      "    - ``'columns'`` : dict like ``{column -> {index -> value}}``\n",
      "    - ``'values'`` : just the values array\n",
      "\n",
      "    The allowed and default values depend on the value\n",
      "    of the `typ` parameter.\n",
      "\n",
      "    * when ``typ == 'series'``,\n",
      "\n",
      "      - allowed orients are ``{'split','records','index'}``\n",
      "      - default is ``'index'``\n",
      "      - The Series index must be unique for orient ``'index'``.\n",
      "\n",
      "    * when ``typ == 'frame'``,\n",
      "\n",
      "      - allowed orients are ``{'split','records','index',\n",
      "        'columns','values', 'table'}``\n",
      "      - default is ``'columns'``\n",
      "      - The DataFrame index must be unique for orients ``'index'`` and\n",
      "        ``'columns'``.\n",
      "      - The DataFrame columns must be unique for orients ``'index'``,\n",
      "        ``'columns'``, and ``'records'``.\n",
      "\n",
      "typ : {'frame', 'series'}, default 'frame'\n",
      "    The type of object to recover.\n",
      "\n",
      "dtype : bool or dict, default None\n",
      "    If True, infer dtypes; if a dict of column to dtype, then use those;\n",
      "    if False, then don't infer dtypes at all, applies only to the data.\n",
      "\n",
      "    For all ``orient`` values except ``'table'``, default is True.\n",
      "\n",
      "    .. versionchanged:: 0.25.0\n",
      "\n",
      "       Not applicable for ``orient='table'``.\n",
      "\n",
      "convert_axes : bool, default None\n",
      "    Try to convert the axes to the proper dtypes.\n",
      "\n",
      "    For all ``orient`` values except ``'table'``, default is True.\n",
      "\n",
      "    .. versionchanged:: 0.25.0\n",
      "\n",
      "       Not applicable for ``orient='table'``.\n",
      "\n",
      "convert_dates : bool or list of str, default True\n",
      "    If True then default datelike columns may be converted (depending on\n",
      "    keep_default_dates).\n",
      "    If False, no dates will be converted.\n",
      "    If a list of column names, then those columns will be converted and\n",
      "    default datelike columns may also be converted (depending on\n",
      "    keep_default_dates).\n",
      "\n",
      "keep_default_dates : bool, default True\n",
      "    If parsing dates (convert_dates is not False), then try to parse the\n",
      "    default datelike columns.\n",
      "    A column label is datelike if\n",
      "\n",
      "    * it ends with ``'_at'``,\n",
      "\n",
      "    * it ends with ``'_time'``,\n",
      "\n",
      "    * it begins with ``'timestamp'``,\n",
      "\n",
      "    * it is ``'modified'``, or\n",
      "\n",
      "    * it is ``'date'``.\n",
      "\n",
      "numpy : bool, default False\n",
      "    Direct decoding to numpy arrays. Supports numeric data only, but\n",
      "    non-numeric column and index labels are supported. Note also that the\n",
      "    JSON ordering MUST be the same for each term if numpy=True.\n",
      "\n",
      "    .. deprecated:: 1.0.0\n",
      "\n",
      "precise_float : bool, default False\n",
      "    Set to enable usage of higher precision (strtod) function when\n",
      "    decoding string to double values. Default (False) is to use fast but\n",
      "    less precise builtin functionality.\n",
      "\n",
      "date_unit : str, default None\n",
      "    The timestamp unit to detect if converting dates. The default behaviour\n",
      "    is to try and detect the correct precision, but if this is not desired\n",
      "    then pass one of 's', 'ms', 'us' or 'ns' to force parsing only seconds,\n",
      "    milliseconds, microseconds or nanoseconds respectively.\n",
      "\n",
      "encoding : str, default is 'utf-8'\n",
      "    The encoding to use to decode py3 bytes.\n",
      "\n",
      "encoding_errors : str, optional, default \"strict\"\n",
      "    How encoding errors are treated. `List of possible values\n",
      "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "lines : bool, default False\n",
      "    Read the file as a json object per line.\n",
      "\n",
      "chunksize : int, optional\n",
      "    Return JsonReader object for iteration.\n",
      "    See the `line-delimited json docs\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#line-delimited-json>`_\n",
      "    for more information on ``chunksize``.\n",
      "    This can only be passed if `lines=True`.\n",
      "    If this is None, the file will be read into memory all at once.\n",
      "\n",
      "    .. versionchanged:: 1.2\n",
      "\n",
      "       ``JsonReader`` is a context manager.\n",
      "\n",
      "compression : str or dict, default 'infer'\n",
      "    For on-the-fly decompression of on-disk data. If 'infer' and 'path_or_buf' is\n",
      "    path-like, then detect compression from the following extensions: '.gz',\n",
      "    '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). If using\n",
      "    'zip', the ZIP file must contain only one data file to be read in. Set to\n",
      "    ``None`` for no decompression. Can also be a dict with key ``'method'`` set\n",
      "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
      "    key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "    ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
      "    example, the following could be passed for Zstandard decompression using a\n",
      "    custom compression dictionary:\n",
      "    ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "\n",
      "    .. versionchanged:: 1.4.0 Zstandard support.\n",
      "\n",
      "nrows : int, optional\n",
      "    The number of lines from the line-delimited jsonfile that has to be read.\n",
      "    This can only be passed if `lines=True`.\n",
      "    If this is None, all the rows will be returned.\n",
      "\n",
      "    .. versionadded:: 1.1\n",
      "\n",
      "storage_options : dict, optional\n",
      "    Extra options that make sense for a particular storage connection, e.g.\n",
      "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "    are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      "    starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      "    ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      "\n",
      "    .. versionadded:: 1.2.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "Series or DataFrame\n",
      "    The type returned depends on the value of `typ`.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.to_json : Convert a DataFrame to a JSON string.\n",
      "Series.to_json : Convert a Series to a JSON string.\n",
      "json_normalize : Normalize semi-structured JSON data into a flat table.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Specific to ``orient='table'``, if a :class:`DataFrame` with a literal\n",
      ":class:`Index` name of `index` gets written with :func:`to_json`, the\n",
      "subsequent read operation will incorrectly set the :class:`Index` name to\n",
      "``None``. This is because `index` is also used by :func:`DataFrame.to_json`\n",
      "to denote a missing :class:`Index` name, and the subsequent\n",
      ":func:`read_json` operation cannot distinguish between the two. The same\n",
      "limitation is encountered with a :class:`MultiIndex` and any names\n",
      "beginning with ``'level_'``.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      "...                   index=['row 1', 'row 2'],\n",
      "...                   columns=['col 1', 'col 2'])\n",
      "\n",
      "Encoding/decoding a Dataframe using ``'split'`` formatted JSON:\n",
      "\n",
      ">>> df.to_json(orient='split')\n",
      "    '{\"columns\":[\"col 1\",\"col 2\"],\"index\":[\"row 1\",\"row 2\"],\"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      ">>> pd.read_json(_, orient='split')\n",
      "      col 1 col 2\n",
      "row 1     a     b\n",
      "row 2     c     d\n",
      "\n",
      "Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      "\n",
      ">>> df.to_json(orient='index')\n",
      "'{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      "\n",
      ">>> pd.read_json(_, orient='index')\n",
      "      col 1 col 2\n",
      "row 1     a     b\n",
      "row 2     c     d\n",
      "\n",
      "Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      "Note that index labels are not preserved with this encoding.\n",
      "\n",
      ">>> df.to_json(orient='records')\n",
      "'[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      ">>> pd.read_json(_, orient='records')\n",
      "  col 1 col 2\n",
      "0     a     b\n",
      "1     c     d\n",
      "\n",
      "Encoding with Table Schema\n",
      "\n",
      ">>> df.to_json(orient='table')\n",
      "    '{\"schema\":{\"fields\":[{\"name\":\"index\",\"type\":\"string\"},{\"name\":\"col 1\",\"type\":\"string\"},{\"name\":\"col 2\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"1.4.0\"},\"data\":[{\"index\":\"row 1\",\"col 1\":\"a\",\"col 2\":\"b\"},{\"index\":\"row 2\",\"col 1\":\"c\",\"col 2\":\"d\"}]}'\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Projects/Internal/bootcamp/itversity-material/ghactivity-aws/ga-venv/lib/python3.9/site-packages/pandas/io/json/_json.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "pd.read_json?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\n",
    "    'data/2022-06-05-0.json.gz',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89443, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'type', 'actor', 'repo', 'payload', 'public', 'created_at',\n",
       "       'org'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                          int64\n",
       "type                       object\n",
       "actor                      object\n",
       "repo                       object\n",
       "payload                    object\n",
       "public                       bool\n",
       "created_at    datetime64[ns, UTC]\n",
       "org                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      NaN\n",
       "1                                                      NaN\n",
       "2                                                      NaN\n",
       "3                                                      NaN\n",
       "4                                                      NaN\n",
       "                               ...                        \n",
       "89438                                                  NaN\n",
       "89439                                                  NaN\n",
       "89440    {'id': 6154722, 'login': 'microsoft', 'gravata...\n",
       "89441    {'id': 6154722, 'login': 'microsoft', 'gravata...\n",
       "89442    {'id': 6154722, 'login': 'microsoft', 'gravata...\n",
       "Name: org, Length: 89443, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['org']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bcd215c4a14989c946b0b0624b2d9cd8bc3b4ff7a1c5d476ef679e9df9c7085"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ga-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
